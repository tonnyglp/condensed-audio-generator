# Condensed Audio Generator

> **Turn any YouTube casual talks (a.k.a Just Chatting) into dense, pauseâ€‘free audio for immersion practice â€” no subtitles required.**

---

## âœ¨  Why I built this

Iâ€™m learning Japanese through **passive immersion**, which means listening to spoken content while doing something else (e.g., walking, commuting, cooking).  
This works well, but casual talks are full of long pauses and backâ€‘channel noises, so the â€œlanguage input per minuteâ€ is low. A **condensed audio** version â€” speech only, no silence â€” makes every minute count.

Existing tools such as **subs2cia** can trim silence **but rely on subtitles** to locate speech. Casual YouTube chats rarely come with accurate captions.

**Condensed Audio Generator** solves the problem automatically:

* downloads a videoâ€™s audio,
* detects speech even over background music,
* removes every nonâ€‘speech gap,
* exports a smooth, evenlyâ€‘paced track you can play on any device.

No subtitles, no manual marking.

---

## âš™ï¸  Features

* **Subtitleâ€‘free VAD** â€“ Silero voiceâ€‘activity detection keeps words, skips silence/BGM  
* **Fullâ€‘band quality** â€“ cuts the original 48 kHz stream; no highâ€‘end loss  
* **Custom padding & breathing gaps** â€“ avoids clipping consonants, keeps a natural rhythm  
* **EBUâ€‘R128 loudness normalisation** â€“ constant volume across chunks  
* **Oneâ€‘command CLI** â†“  

```bash
python condense.py <VIDEO_URL>
```

* Output formats: **MP3 192 kb/s** (default), Opus, FLAC, WAV  
* Runs on CPU; GPU (CUDA) optional for faster processing  

---

## ğŸš€  Quickâ€‘start

### 1. Clone the repo

```bash
git clone https://github.com/tonnyglp/condensed-audio-generator.git
cd condensed-audio-generator
```

### 2. Create & activate a virtual environment

| Platform | Create venv | **Activate** |
|----------|-------------|--------------|
| **macOS / Linux (bash/zsh)** | `python3 -m venv .venv` | `source .venv/bin/activate` |
| **Windows â€“ PowerShell** | `python -m venv .venv` | `.venv\Scripts\Activate.ps1` |
| **Windows â€“ cmd.exe** | `python -m venv .venv` | `.venv\Scripts\activate.bat` |

If PowerShellâ€™s execution policy blocks the script, run `Setâ€‘ExecutionPolicy -Scope Process RemoteSigned` once in the same window.

> **System requirement:** python3 and python3-venv must be installed and available on your `PATH`.

### 3. Install dependencies

Upgrade `pip`:

```bash
python -m pip install -U pip
```

For dependencies, a `requirements.txt` is provided.

```bash
pip install -r requirements.txt
```

> **System requirement:** FFmpeg (â‰¥ 4.4) must be installed separately and available on your `PATH`.

*(If you prefer a minimal install, see the â€œDependenciesâ€ section below.)*

### 4. Generate condensed audio

```bash
python condense.py <VIDEO_URL>
```

The finished file appears in `output/`:

```
output/
â””â”€â”€ d853dc6cc29d4186bfd58355dce58fd1_dense.mp3
```

### Optional: when youâ€™re done, leave the venv

```bash
deactivate
```

---

## ğŸ”„ Nextâ€‘time (everyday) usage

Once youâ€™ve cloned the repo, set up the venv, and installed the requirements, future runs are just three short commands.

```text
# 1. Open a terminal / PowerShell / cmd and cd into the repo:
cd condensed-audio-generator

# 2. Activate the virtual environment:
macOS / Linux  :  source .venv/bin/activate
Windows (PS)   :  .venv\Scripts\Activate.ps1
Windows (cmd)  :  .venv\Scripts\activate.bat

# 3. Run the tool with any options you like:
python condense.py <VIDEO_URL> [--format mp3|opus|flac|wav] [--pad 200] â€¦

# Optional: when youâ€™re done, leave the venv
deactivate
```

Thatâ€™s allâ€”youâ€™re ready to create dense, pauseâ€‘free audio whenever you want, with no additional setup.

---

## ğŸ“¦  Dependencies

| Package | Why | Tested version |
|---------|-----|----------------|
| **ytâ€‘dlp** | Download bestâ€‘quality audio | 2025.03.31 |
| **torch 2.2.0 + torchaudio** | backend for Sileroâ€‘VAD | 2.2.0 |
| **sileroâ€‘vad** | lightâ€‘weight JIT VAD model | 5.1.2 |
| **pydub** & **ffmpeg** | slicing, encoding | pydub 0.25.1 â€¢ ffmpeg 6.1.1 |
| **soundfile, numpy\<2** | reading WAV, array ops | 0.13.1 â€¢ 1.26.4 |

> **Note:** PyTorch â‰¤ 2.2 wheels expect **NumPy 1.x**, so the requirements file pins `numpy<2` to avoid ABI errors.

---

## ğŸ“„  Usage

```text
usage: condense.py URL [--outdir DIR] [--format {mp3,opus,flac,wav}]
                       [--merge GAP] [--pad MS] [--gap MS]

positional arguments:
  URL                   YouTube link

options:
  --outdir DIR          destination folder (default: output/)
  --format â€¦            mp3 | opus | flac | wav  (default: mp3)
  --merge GAP           merge segments â‰¤ GAP (s) apart (default: 1.0)
  --pad MS              pad each kept chunk (ms)   (default: 250)
  --gap MS              silence inserted between chunks (default: 0)
```

---

## ğŸ—ï¸  How it works

1. **ytâ€‘dlp** downloads best audio â†’ `original.wav` (48 kHz stereo)  
2. **ffmpeg** makes a mono 16 kHz copy for VAD  
3. **Sileroâ€‘VAD** finds speech frames â†’ `[start, end]` intervals  
4. Intervals are **padded** Â± `--pad` ms & **merged** if closer than `--merge` s  
5. **pydub** slices the *original* 48 kHz file, inserts `--gap` ms silence between pieces  
6. **ffmpeg** applies EBUâ€‘R128 `loudnorm` and encodes (MP3, Opusâ€¦)  

---

## ğŸ—ºï¸  Roadmap / TODO

* Keep original YouTube title for the output filename âœ…  
* Confirmed support for multiple languages (Japanese, Chinese, English, â€¦) âœ…  
* Add fadeâ€‘in/out to remove clicks  
* Performance improvement (target: 2 min for 2 h video)  

PRs and ideas are very welcome.

---

## ğŸ™  Acknowledgements

* **Silero** â€“ multilingual VAD model  
* **ytâ€‘dlp** â€“ robust YouTube extraction  
* **FFmpeg** & **PyDub** â€“ the audio workhorses  
* Inspiration from **subs2cia**

---

## âš ï¸  Disclaimer

Downloading YouTube content may violate YouTubeâ€™s Terms of Service in your
jurisdiction. This tool is provided **for personal study only**; you are
responsible for ensuring you have the right to download and process any media.

---

> Â© 2025â€ƒMaintained by [**@tonnyglp**](https://github.com/tonnyglp)
