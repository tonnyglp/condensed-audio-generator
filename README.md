# Condensed Audio Generator

> **Turn any Japanese YouTube conversation into dense, pauseâ€‘free audio for immersion practice â€” no subtitles required.**

[![Python](https://img.shields.io/badge/python-3.9%2B-blue.svg)](https://www.python.org/)â€‚[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](#license)â€‚[![CI](https://img.shields.io/github/actions/workflow/status/tonnyglp/condensed-audio-generator/tests.yml?label=CI)](https://github.com/tonnyglp/condensed-audio-generator/actions)

---

## âœ¨ Â Why I built this

Iâ€™m learning Japanese through â€œimmersion listeningâ€.  
Existing tools such as **subs2cia** can trim silence **but rely on subtitles** to know where speech happens. Casual YouTube chats rarely come with accurate subs â€” and manual captionâ€‘cleaning is tedious.

**Condensed Audio Generator** does the same job **automatically**:

* downloads a videoâ€™s audio,
* detects speech even over background music,
* chops out every nonâ€‘speech gap,
* exports a smooth, evenlyâ€‘paced track you can loop on your phone.

No subtitles, no handâ€‘marking.

---

## âš™ï¸ Â Features

* **Subtitleâ€‘free VAD** â€“ Silero voiceâ€‘activity detection keeps words, skips silence/BGM  
* **Fullâ€‘band quality** â€“ cuts the original 48Â kHz stream; no highâ€‘end loss  
* **Custom padding & breathing gaps** â€“ avoids clipping consonants, keeps natural rhythm  
* **EBUâ€‘R128 loudness normalisation** â€“ constant volume across all chunks  
* **Oneâ€‘command CLI**:  

```bash
python condense.py https://youtu.be/VIDEO_ID
```

* Output formats: **MP3Â 192Â kb/s** (default), Opus, FLAC, WAV  
* Works on CPU; GPU optional for faster runs  
* Clean **MIT** licence

---

## ğŸš€ Â Quickâ€‘start

```bash
# 1. clone
git clone https://github.com/tonnyglp/condensed-audio-generator.git
cd condensed-audio-generator

# 2. create & activate venv
python3 -m venv .venv
source .venv/bin/activate
python -m pip install -U pip

# 3. install deps (NumPy 1.x for PyTorch 2.2 wheels)
pip install -r requirements.txt          # or: pip install yt-dlp torch torchaudio ...

# 4. generate condensed audio
python condense.py https://www.youtube.com/watch?v=dQw4w9WgXcQ
```

The result appears in `output/` with the **same title as the video**:

```
output/
â””â”€â”€ ã€æ—¥æœ¬èªé›‘è«‡ã€‘æ¨ã—æ¼«ç”»ã¨ã‚²ãƒ¼ãƒ _dense.mp3
```

---

## ğŸ“„ Â Usage

```text
usage: condense.py URL [--outdir DIR] [--format {mp3,opus,flac,wav}]
                       [--merge GAP] [--pad MS] [--gap MS]

positional arguments:
  URL                   YouTube link

options:
  --outdir DIR          destination folder (default: output/)
  --format â€¦            mp3 | opus | flac | wav  (default: mp3)
  --merge GAP           merge segments â‰¤Â GAPÂ s apart (default: 0.30)
  --pad MS              pad every kept chunk (ms)   (default: 80)
  --gap MS              silence inserted between chunks (default: 150)
```

### Example

```bash
# Podcastâ€‘like pacing, Opus 160Â kb/s
python condense.py https://youtu.be/abcdef --merge 0.4 --gap 250 --format opus
```

---

## ğŸ—ï¸ Â How it works

1. **ytâ€‘dlp** downloads best audio â†’ `original.wav` (48Â kHz stereo)  
2. **ffmpeg** makes a mono 16Â kHz **copy** for VAD  
3. **Sileroâ€‘VAD** finds speech frames â†’ `[start, end]` intervals  
4. Intervals are **padded** Â±Â `--pad`Â ms & **merged** if closer than `--merge`Â s  
5. **pydub** slices the *original* 48Â kHz file, inserts `--gap`Â ms silence between pieces  
6. **ffmpeg** applies EBUâ€‘R128 `loudnorm` and encodes (MP3, Opusâ€¦)  

Total time: ~Â 8Â min for a 2Â h chat on M2 Air (ARMâ€‘CPU only).

---

## ğŸ—ºï¸ Â Roadmap / TODO

* [ ] **Keep original YouTube title** for output filename (done!)  
* [ ] 5Â ms fadeâ€‘in/out to remove clicks  
* [ ] Performance: explore parallel chunk rendering to drop 2Â h â†’ 2Â min  
* [ ] Interactive GUI (Streamlit)  
* [ ] Docker image & PyPI package  

Contributions welcome â€” see below!

---

## ğŸ¤ Â Contributing

1. Fork & create a feature branch.  
2. Follow **black**, **isort**, **ruff** for linting.  
3. Run `pytest`.  
4. Open a PR; GitHubÂ CI will run the tests.

Please file bugs or feature requests via **GitHub Issues**.

---

## ğŸ™ Â Acknowledgements

* **Silero team** for the tiny, multilingual VAD model  
* **ytâ€‘dlp** community for robust YouTube extraction  
* **FFmpeg** & **PyDub** projects  
* Inspiration from **subs2cia**

---

## âš ï¸ Â Disclaimer

Downloading YouTube content may violate YouTubeâ€™s Terms of Service in your
jurisdiction.Â This tool is provided **for personalâ€‘use study only**; you are
responsible for ensuring you have the right to download and process any media.

---

## ğŸ“œ Â License

This project is released under the **MIT License**.  
See [`LICENSE`](LICENSE) for full text.

---

> 2025â€ƒÂ·â€ƒMaintained by [**@tonnyglp**](https://github.com/tonnyglp)
